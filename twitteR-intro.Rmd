---
title: "TwitteR: introductory session"
author: "Mik Black"
date: "2 August 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This material covers a VERY basic introduction to some of the functionality provided by the `twitteR` package for R.

It borrows heavily from multiple sources: 

 - https://github.com/pablobarbera/social-media-workshop
 - http://www.rdatamining.com/docs/r-and-data-mining-examples-and-case-studies
 - http://www.r-bloggers.com/playing-with-twitter-data/

### R libraries

The main R package used during this session is `twitteR`.  You can install this via:

```{r eval=FALSE}
install.packages("twitteR", repos="http://cran.stat.auckland.ac.nz")
```

### Getting started

In order to use the Twitter API* to gather data, you need to create a "Twitter app" (you also need a Twitter account).  This process generates an authentication tiken that can be used from within R to gain access to tweet data via the API.

 - Step 1: go to apps.twitter.com and sign in
 - Step 2: click on "Create New App"
 - Step 3: fill name, description, and website (it can be any website): make sure you leave 'Callback URL' empty.
 - Step 4: agree to user conditions
 - Step 5: get key and token information from "Keys and Access Tokens" tab: copy these and paste them into the R code below.

 *API = Application program interface: "set of routine definitions, protocols, and tools for building software and applications. A good API makes it easier to develop a program by providing all the building blocks, which are then put together by the programmer": https://en.wikipedia.org/wiki/Application_programming_interface

### Using the token info in R

```{r eval=FALSE}
consumerKey = "XXXXXXXXXXXX"
consumerSecret = "YYYYYYYYYYYYYYYYYYY"
accessToken = "ZZZZZZZZZZZZZZ"
accessSecret = "AAAAAAAAAAAAAAAAAA"

library(twitteR)
setup_twitter_oauth(consumer_key=consumerKey, consumer_secret=consumerSecret,
		    access_token=accessToken, access_secret=accessSecret)
```

### Using the twitteR package

The first step is to send the authentication information to twitter.

__NB: I'm assuming that we are starting from this point, and the code above hasn't yet been run.__

```{r}
rm(list=ls())
library(twitteR)

## Enter your key/token info below
consumerKey = "XXXXXXXXXXXX"
consumerSecret = "YYYYYYYYYYYYYYYYYYY"
accessToken = "ZZZZZZZZZZZZZZ"
accessSecret = "AAAAAAAAAAAAAAAAAA"

## Alternative: save key/token info to separate file 
source('myKeyData.R')

## Authenticate with Twitter
setup_twitter_oauth(consumer_key=consumerKey, consumer_secret=consumerSecret,
                    access_token=accessToken, access_secret=accessSecret)
```

Once the token information is set up, it can be used to query timeline data via the twitter API.  Let's make a basic query to retrieve the last tweet that mentioned the word "highlanders".

```{r}
searchTwitter('highlanders', n=1)
```

### Examining a twitter timeline

Retrieve the last 20 tweets from the NZ Prime Minister

```{r, cache=TRUE}
keyTweets <- userTimeline("johnkeypm", n=20)
```

How many did we get?

```{r}
length(keyTweets)
```

Lets look at the first few (most recent)

```{r}
head(keyTweets)
```

What type of objects are we dealing with?

```{r}
class(keyTweets)
class(keyTweets[[1]])
```

The tweets are a list of "status" objects that are specific to the twitteR package.  What else can we find out about these?

```{r}
## Below is equivalent to: getClass("status")
getClass(class(keyTweets[[1]]))
```

There are a lot of additional fields of information available for each tweet:

```{r}
## Display the text of the first tweet
keyTweets[[1]]$text

## Display the time of the first tweet
keyTweets[[1]]$created
```

In order to make access to these fields easier, `twitteR` provides a function to convert the list of tweets into a data frame:

```{r}
## Convert to data frame
keyTweetsDf <- twListToDF(keyTweets)

## Check dimensions
dim(keyTweetsDf)

## Examine first row (most recent tweet)
keyTweetsDf[1,]
```

### Sentiment analysis

The idea of "sentiment analysis" can be used to assess the sentiment (e.g., positive or negative) of a tweet.

There are a few ways to do this (using additional packages), but we are going to use a "first principles" approach, as taken in this workshop:

https://github.com/pablobarbera/social-media-workshop

First, lets load a data set of positive and negative words:

```{r}
# loading lexicon of positive and negative words (from Github repo above)
lexicon <- read.csv("lexicon.csv", stringsAsFactors=F)
pos.words <- lexicon$word[lexicon$polarity=="positive"]
neg.words <- lexicon$word[lexicon$polarity=="negative"]

# a look at a random sample of positive and negative words
sample(pos.words, 10)
sample(neg.words, 10)
```

Next we'll load some helper functions (again, courtesy of the Github repo above) to handle the 
processing of the tweet data:

```{r}
## Load helper functions
source('twitteR-intro-helper-functions.R')
```

The functions are:

 - `clean_tweets`: split each tweet into individual words, and remove special characters.
 - `classify`: score the overall "positivity" or "negativity" of a tweet, based 
    on the numbers of positive and negative words it contains.
 - `classifer`: applies the `classify` function to a collection of tweets, and 
    returns aggregated statistics.

Before we get started on our sentiment analysis, let's generate some more data:

```{r, cache=TRUE}
## Retrieve tweet data for Obama, Trump and Clinton.
obamaTweets <- userTimeline("BarackObama", n=3200)
trumpTweets <- userTimeline("realDonaldTrump", n=3200)
clintonTweets <- userTimeline("HillaryClinton", n=3200)
```

```{r}
## Check lengths
length(obamaTweets)
length(trumpTweets)
length(clintonTweets)

## Convert each list to a data frame
obamaDf <- twListToDF(obamaTweets)
trumpDf <- twListToDF(trumpTweets)
clintonDf <- twListToDF(clintonTweets)
```

Now apply the helper fuctions to our data.

```{r}
## Clean tweets
obamaText <- clean_tweets(obamaDf$text)
trumpText <- clean_tweets(trumpDf$text)
clintonText <- clean_tweets(clintonDf$text)
```

What did that do?
```{r}
## Original tweet
obamaDf$text[1]

## Clean tweet
obamaText[1]
```

```{r, fig.height=8}
par(mfrow=c(2,2))
## Histograms of tweet length
hist(unlist(lapply(obamaText,length)), col=grey(0.8), main="Obama: tweet lengths")
hist(unlist(lapply(trumpText,length)), col='lightpink', main="Trump: tweet lengths")
hist(unlist(lapply(clintonText,length)), col='lightblue', main="Clinton: tweet lengths")

## Tweet length density plots
plot(density(unlist(lapply(obamaText,length))), main="Tweet length densities")
lines(density(unlist(lapply(trumpText,length))), col='red')
lines(density(unlist(lapply(clintonText,length))), col='blue')
legend('topleft', c("Obama","Trump","Clinton"), fill=c("black", "red", "blue"))
```

### Sentiment analysis

Use the `classify` function to assess the positive/negative content of a tweet:

```{r}
classify(obamaText[[1]], pos.words, neg.words)
```

Apply to all tweets (for once I won't use `lapply`...):

```{r}
## Calculate scores for every Obama tweet
obamaScore <- c()
for(i in 1:length(obamaText)){
  obamaScore[i] <- classify(obamaText[[i]], pos.words, neg.words)
}
## Display scores
obamaScore
## What was the range of scores?
range(obamaScore)

## Which was the highest score?
which.max(obamaScore)
## What was that tweet?
obamaTweets[[which.max(obamaScore)]]

## Which was the lowest score?
which.min(obamaScore)
## What was that tweet?
obamaTweets[[which.min(obamaScore)]]
```

Sentiment analysis seems to be an inexact art...

__Challenge: what were Donald Trump's most positive and most negative tweets?__

```{r, echo=FALSE, eval=FALSE}
trumpScore <- c()
for(i in 1:length(trumpText)){
  trumpScore[i] <- classify(trumpText[[i]], pos.words, neg.words)
}
## Display scores
trumpScore
## What was the range of scores?
range(trumpScore)

## Which was the highest score?
which.max(trumpScore)
## What was that tweet?
trumpTweets[[which.max(trumpScore)]]

## Which was the lowest score?
which.min(trumpScore)
## What was that tweet?
trumpTweets[[which.min(trumpScore)]]
```

### Sentiment analysis: final task

Apply the `classifier` function to aggregate scores across all tweets for each user.

```{r}
# applying classifier function
classifier(obamaText, pos.words, neg.words)
classifier(trumpText, pos.words, neg.words)
classifier(clintonText, pos.words, neg.words)
```

## Searching twitter

We can also search twitter for particular words (including hashtags), using the `searchTwitter` function.
The code below searches for the last 1000 tweets containing "donaldtrump" "barrackobama" or "hillaryclinton".  Using the commands we learned above, we can then perform a sentiment analysis for the tweets relating to each search term.

```{r, cache=TRUE}
tweetTrump = searchTwitter('donaldtrump', n = 1000)
tweetTrumpDf <- twListToDF(tweetTrump)
tweetTrumpText <- clean_tweets(tweetTrumpDf$text)
classifier(tweetTrumpText, pos.words, neg.words)
```

```{r, cache=TRUE}
tweetObama = searchTwitter('barackobama', n = 1000)
tweetObamaDf <- twListToDF(tweetObama)
tweetObamaText <- clean_tweets(tweetObamaDf$text)
classifier(tweetObamaText, pos.words, neg.words)
```

```{r, cache=TRUE}
tweetClinton = searchTwitter('hillaryclinton', n = 1000)
tweetClintonDf <- twListToDF(tweetClinton)
tweetClintonText <- clean_tweets(tweetClintonDf$text)
classifier(tweetClintonText, pos.words, neg.words)
```

## Final thoughts

This has only just scratched the surface of what can be accomplished by mining twitter data (or Facebook, or Instagram).  Have a look at the following links (rbloggers articles) for some more ideas: 

 - https://www.r-bloggers.com/?s=twitter
 - https://www.r-bloggers.com/?s=facebook
 - https://www.r-bloggers.com/?s=instagram


```{r, echo=FALSE, eval=FALSE}
plot(obamaDf$created, 
     unlist(lapply(obamaText,classify, pos.words, neg.words)), 
     type='line')

lines(trumpDf$created, 
      unlist(lapply(trumpText,classify, pos.words, neg.words)),
      col='red')
      
lines(clintonDf$created, 
      unlist(lapply(clintonText,classify, pos.words, neg.words)),
      col='blue')

####

tw = searchTwitter('#nzgenomics', n = 1e4, since = '2016-01-01')
twDf <- twListToDF(tw)
```